# --- Ù…Ø±Ø­Ù„Ù‡ Û±: Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ ---
from google.colab import drive
drive.mount('/content/drive')

import os

# --- Ù…Ø±Ø­Ù„Ù‡ Û²: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ ---

# Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ Ø¯Ø± Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù‡Ù…Ù‡ Ú†ÛŒØ²
base_dir = "/content/drive/MyDrive/AI_Offline_Repo_FULL"
# Ù†Ø§Ù… ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ
archive_name = "AI_Offline_Repo_FULL.tar.gz"
archive_path = f"/content/drive/MyDrive/{archive_name}"

# Ù„ÛŒØ³Øª Ú©Ø§Ù…Ù„ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒØªÙˆÙ† (ØªØ±Ú©ÛŒØ¨ Ù„ÛŒØ³Øª Ù‚Ø¨Ù„ÛŒ Ùˆ Ù„ÛŒØ³Øª Ø´Ù…Ø§ Ø¨Ø§ Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ)
python_libraries = list(set([
    # Core AI & ML
    "torch", "torchvision", "torchaudio", "tensorflow", "transformers", "accelerate", "bitsandbytes",
    "datasets", "peft", "Pillow", "sentence-transformers", "tqdm",
    # LangChain Ecosystem
    "langchain", "langchain-community", "langchain-text-splitters", "chromadb",
    # Data Handling & PDF
    "PyMuPDF", "pdf2image", "PyYAML",
    # App & UI
    "streamlit", "streamlit-mermaid", "gradio",
    # Other Essentials
    "huggingface_hub", "jupyter", "faiss-cpu"
]))

# Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ (ÙØ±Ù…Øª GGUF Ø§Ø² TheBloke)
# Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù‡Ø± Ù…Ø¯Ù„ÛŒ Ø±Ø§ Ú©Ù‡ Ù†Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¨Ø§ Ú¯Ø°Ø§Ø´ØªÙ† # Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ Ø®Ø· Ø¢Ù†ØŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
models_to_download = {
    # Gemma Models
    "gemma-2b-it": "TheBloke/gemma-2b-it-GGUF/gemma-2b-it.Q4_K_M.gguf",
    "gemma-7b-it": "TheBloke/gemma-7b-it-GGUF/gemma-7b-it.Q5_K_M.gguf",
    # Llama 3 Models
    "llama-3-8b-instruct": "TheBloke/Meta-Llama-3-8B-Instruct-GGUF/meta-llama-3-8b-instruct.Q4_K_M.gguf",
    "llama-3-70b-instruct": "TheBloke/Meta-Llama-3-70B-Instruct-GGUF/meta-llama-3-70b-instruct.Q4_K_M.gguf", # Ù‡Ø´Ø¯Ø§Ø±: Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø²Ø±Ú¯ Ø§Ø³Øª (Ø­Ø¯ÙˆØ¯ Û´Û° Ú¯ÛŒÚ¯)
    # DeepSeek Models
    "deepseek-coder-v2-lite": "TheBloke/deepseek-coder-v2-lite-instruct-GGUF/deepseek-coder-v2-lite-instruct.Q4_K_M.gguf",
    "deepseek-llm-7b-chat": "TheBloke/deepseek-llm-7b-chat-GGUF/deepseek-llm-7b-chat.Q5_K_M.gguf",
    # Qwen Models
    "qwen-1.5-4b-chat": "TheBloke/Qwen1.5-4B-Chat-GGUF/qwen1_5-4b-chat.Q5_K_M.gguf",
    "qwen-1.5-14b-chat": "TheBloke/Qwen1.5-14B-Chat-GGUF/qwen1_5-14b-chat.Q5_K_M.gguf"
}

# --- Ù…Ø±Ø­Ù„Ù‡ Û³: Ø³Ø§Ø®Øª Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ ---

pypi_dir = os.path.join(base_dir, "PyPI_Libraries")
models_dir = os.path.join(base_dir, "AI_Models")
github_dir = os.path.join(base_dir, "GitHub_Tools")

os.makedirs(pypi_dir, exist_ok=True)
os.makedirs(models_dir, exist_ok=True)
os.makedirs(github_dir, exist_ok=True)
print(f"Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡ Ø¯Ø± Ù…Ø³ÛŒØ± {base_dir} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.")

# Û±. Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ PyPI
print("\nâ³ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ PyPI...")
requirements_path = "/content/requirements.txt"
with open(requirements_path, "w") as f:
    f.write("\n".join(python_libraries))
!pip download -r {requirements_path} -d {pypi_dir}
print("âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ PyPI ØªÙ…Ø§Ù… Ø´Ø¯.")

# Û². Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
print("\nâ³ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...")
!pip install -q huggingface_hub
for name, path in models_to_download.items():
    repo_id, filename = path.split('/')
    print(f"--- Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„: {name} ---")
    !huggingface-cli download {repo_id} {filename} --local-dir {models_dir}/{name} --local-dir-use-symlinks False
print("âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØªÙ…Ø§Ù… Ø´Ø¯.")

# Û³. Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨
print("\nâ³ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ (llama.cpp Ùˆ text-generation-webui)...")
!git clone https://github.com/ggerganov/llama.cpp.git {github_dir}/llama.cpp
!git clone https://github.com/oobabooga/text-generation-webui.git {github_dir}/text-generation-webui
print("âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ ØªÙ…Ø§Ù… Ø´Ø¯.")


# --- Ù…Ø±Ø­Ù„Ù‡ Û´: ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù‡Ù…Ù‡ Ú†ÛŒØ² Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„ ---
print(f"\nâ³ Ø´Ø±ÙˆØ¹ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù„ Ù¾ÙˆØ´Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ {archive_name}...")
# Ø§ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ø­Ø¬Ù… Ú©Ù„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø³ÛŒØ§Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø´ÙˆØ¯
!tar -czf {archive_path} -C {os.path.dirname(base_dir)} {os.path.basename(base_dir)}

print("\nğŸ‰ğŸ‰ğŸ‰ Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙ…Ø§Ù… Ø´Ø¯! ğŸ‰ğŸ‰ğŸ‰")
print(f"ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡ Ú©Ø§Ù…Ù„ Ø¯Ø± Ù…Ø³ÛŒØ± Ø²ÛŒØ± Ø¯Ø± Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ Ø´Ù…Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯:\n{archive_path}")
